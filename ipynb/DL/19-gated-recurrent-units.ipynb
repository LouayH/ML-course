{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated Recurrent Unit\n",
    "\n",
    "GRU is a type of RNN that is similar to LSTM's structure, which enable sequential model to remember or forget information, also it's simpler than LSTM's structure, with a fewer parameters, which can make it easier to train and more computationally efficient. \n",
    "\n",
    "The main difference between GRU and LSTM is how the flow of information is controlled, in LSTM the memory cell has 3 gates and is maintained separtely from the **Hidden state**.\n",
    "\n",
    "In GRU, the memory cell is replaced with a **candidate activation vector** which is updated using <u>2 gates</u>:\n",
    "\n",
    "* Reset gate determines how much of the previous hidden state to forget\n",
    "* Update gate determines how much of the candidate activation vector to incorporate into the new hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reviews = [\n",
    "  \"I liked the movie, it was fantastic!\",\n",
    "  \"The food was terrible, I won't recommend it.\",\n",
    "  \"The book was amazing, couldn't put it down.\",\n",
    "  \"It was a terrible film\"\n",
    "]\n",
    "\n",
    "sentiments = np.array([1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 6, 3, 7, 1, 2, 8],\n",
       " [3, 9, 2, 5, 4, 10, 11, 1],\n",
       " [3, 12, 2, 13, 14, 15, 1, 16],\n",
       " [1, 2, 17, 5, 18]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'it': 1,\n",
       " 'was': 2,\n",
       " 'the': 3,\n",
       " 'i': 4,\n",
       " 'terrible': 5,\n",
       " 'liked': 6,\n",
       " 'movie': 7,\n",
       " 'fantastic': 8,\n",
       " 'food': 9,\n",
       " \"won't\": 10,\n",
       " 'recommend': 11,\n",
       " 'book': 12,\n",
       " 'amazing': 13,\n",
       " \"couldn't\": 14,\n",
       " 'put': 15,\n",
       " 'down': 16,\n",
       " 'a': 17,\n",
       " 'film': 18}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  4,  6,  3,  7,  1,  2,  8],\n",
       "       [ 3,  9,  2,  5,  4, 10, 11,  1],\n",
       "       [ 3, 12,  2, 13, 14, 15,  1, 16],\n",
       "       [ 0,  0,  0,  1,  2, 17,  5, 18]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_length = max([len(sequence) for sequence in sequences])\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen = max_sequence_length)\n",
    "\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, GRU, Dense\n",
    "\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 32\n",
    "\n",
    "model = Sequential([\n",
    "  Input(shape = (max_sequence_length, )),\n",
    "  Embedding(input_dim = vocab_size, output_dim = embedding_dim),\n",
    "  GRU(32),\n",
    "  Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.2667 - loss: 0.6986     \n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6891  \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6823  \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5333 - loss: 0.6882     \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 0.6715  \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.6614 \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.6497  \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6493  \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.6266  \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.6309 \n"
     ]
    }
   ],
   "source": [
    "model_output = model.fit(sequences, sentiments, batch_size = 1, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.6061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6061344146728516, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(sequences, sentiments)\n",
    "\n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Positive Review: The food was fantastic!\n",
      "Negative Review: The movie was terrible\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\n",
    "  \"The food was fantastic!\",\n",
    "  \"The movie was terrible\"\n",
    "]\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sample_data)\n",
    "sequences = pad_sequences(sequences, maxlen = max_sequence_length)\n",
    "\n",
    "predictions = model.predict(sequences)\n",
    "\n",
    "for review, prediction in zip(sample_data, predictions):\n",
    "  sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "  print(f\"{sentiment} Review: {review}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
